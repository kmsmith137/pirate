import os
import re
import numpy as np

from . import utils
from .utils import srange

from .Dtype import Dtype
from .Kernel import Kernel
from .Ringbuf import Ringbuf
from .FrequencySubbands import FrequencySubbands


# Peak-finding kernel parameterization:
#
#  - frequency_subbands  (compile-time)
#  - Dcore               (compile-time)
#  - Dout                (compile-time, also denoted nt_in_per_out)
#  - E                   (compile-time)
#  - frequency_subbands  (compile-time)
#  - nt_in               (runtime)
#  - ndm_out_per_wt      (runtime)
#  - nt_in_per_wt        (combination, see below)
#
# Note that there is no 'ndm_in_per_out' parameter, since the "uncoalesced"
# peak-finding kernel doesn't care about input DMs.
#
# Constraints:
#
#   - All of these must be a power of two, except nt_in
#   - nt_in is a multiple of nt_in_per_wt
#   - nt_in is a multiple of (32*SW), where SW = 32/sizeof(dtype) is the simd width
#   - nt_in_per_wt must be a multiple of Dout (= nt_in_per_out)   (*)
#   - SW <= Dcore <= Dout <= 32
#   - E <= 32
#
# There is also a compile-time parameter 'Tinner' which is derived from 'nt_in_per_wt':
#
#   Tinner = max(32*SW/nt_in_per_wt, 1)             (**)
#
# (In the kernel, Tinner = "number of tw-samples per 128-byte cache line".)
#
# From the perspective of the kernel, 'Tinner' is a compile-time parameter, and the
# caller passes 'nt_in_per_wt' at runtime. If Tinner > 1, then the value of 'nt_in_per_wt'
# is ignored. If Tinner==1, then 'nt_in_per_wt' must divide (32*SW).
#
# From the perspective of the host C++ code, 'nt_in_per_wt' is the only parameter.
# The host derives Tinner using (*) and loads the appropriate kernel from the registry.
# At runtime, the value of 'nt_in_per_wt' is passed to the kernel. (This is redundant
# if nt_in_per_wt < 32*SW, but the host doesn't need to know that.)
#
# Note that the runtime constraints (*) and (**) imply the compile-time constraint:
#
#   Dout * Tinner <= (32*SW)       (***)


####################################################################################################


class PeakFinder2:
    def __init__(self, dtype, frequency_subbands, E, Dcore, Dout, Tinner):
        self.dtype = dtype = Dtype(dtype)
        self.frequency_subbands = frequency_subbands                                            
        self.Tinner = Tinner
        self.Dcore = Dcore
        self.Dout = Dout
        self.E = E

        self.dt32 = dtype.simd32
        self.SW = dtype.simd_width

        # See constraints above
        assert utils.is_power_of_two(E)
        assert utils.is_power_of_two(Dout)
        assert utils.is_power_of_two(Dcore)
        assert utils.is_power_of_two(Tinner)

        assert E <= 32
        assert Dout <= 32
        assert Dcore <= Dout
        assert self.SW <= Dcore
        assert Dout*Tinner <= (32 * self.SW)    # see (***) above

        self.P = 3 * utils.integer_log2(E) + 1   # number of peak-finding profiles
        self.weight_reader = PfWeightReader(frequency_subbands, dtype, Dcore, self.P, Tinner)
        self.weight_layout = self.weight_reader.weight_layout
        self.output = PfOutput2(dtype, Dout)
        
        self.M = self.weight_reader.M
        self.Mouter = self.weight_reader.Mouter
        self.Minner = self.weight_reader.Minner
        self.Pouter = self.weight_layout.Pouter
        self.Pinner = self.weight_layout.Pinner
        self.wt_touter_byte_stride = self.weight_layout.touter_byte_stride

        self.pfx_nb = utils.integer_log2(self.SW)
        self.pfx_nl = utils.integer_log2(self.Dcore) - self.pfx_nb
        self.pfys_held = set()
        self.pfz_decl = set()

        self.rb = Ringbuf(self.dt32)
        self.pf_output = PfOutput2(dtype, Dout)
        self.pf_weight_reader = PfWeightReader(frequency_subbands, dtype, Dcore, self.P, Tinner)
        
        # Typical kernel name: pf2_fp32_f11_f6_f3_f1_E16_Dcore8_Dout16_Tinner1
        self.kernel_name = f'pf2_{dtype.fname}_{frequency_subbands.fstr}_E{E}_Dcore{Dcore}_Dout{Dout}_Tinner{Tinner}'
        self.kernel_basename = self.kernel_name + '.cu'

        # For testing: if a peak-finding kernel is precompiled, we also precompile unit tests
        # for the associated 'weight_reader' and 'output' microkernels.
        self.all_kernel_basenames = [
            self.kernel_basename,
            self.weight_reader.test_kernel_basename,
            self.output.test_kernel_basename
        ]


    @classmethod
    def _idiv(cls, var, n):
        return f'({var} >> {utils.integer_log2(n)})' if (n != 1) else var
        
    def emit_kernel(self, k):
        dt32, SW, Dcore, Dout, M = self.dt32, self.dtype.simd_width, self.Dcore, self.Dout, self.M

        k.emit('// Autogenerated by pirate_frb.cuda_generator')
        k.emit()
        k.emit('// For a high-level overview, see the long comment at the top of')
        k.emit('// pirate_frb/cuda_generator/PeakFinder.py')
        k.emit()
        k.emit('#include "../../include/pirate/PeakFindingKernel.hpp"')
        k.emit('#include "../../include/pirate/inlines.hpp"  // vec_equal()')
        k.emit()
        k.emit('#include <cstdio>')
        k.emit('#include <iostream>')
        k.emit()
        k.emit('namespace pirate {')
        k.emit()
        k.emit('// Each warp processes a shape (M,nt_in) input array (one beam, one output DM)')
        k.emit('// Launch with B blocks, {32,W,1} threads.')
        k.emit('//')
        k.emit('// in: shape (B*W, M, nt_in)')
        k.emit('// out_max: shape (B*W, nt_in/Dout)')
        k.emit('// out_argmax: shape (B*W, nt_in/Dout)')
        k.emit('// wt: complicated format (from class PfWeightLayout, see below)')
        k.emit('// pstate: (B*W, PW32) where PW32 = pstate 32-bit registers per warp')
        k.emit('// nt_in: number of input time samples')
        k.emit('// ndm_out_per_wt: dm downsampling factor for weight array (relative to *output*)')
        k.emit('// nt_in_per_wt: time downsampling factor for weight array (relative to *input*)')
        k.emit('//')
        k.emit('// Caller is responsible for checking:')
        k.emit('//   - ndm_out_per_wt and nt_in_per_wt are powers of two')
        k.emit('//   - If Tinner == 1, then nt_in_per_wt >= (32 * simd_width)')
        k.emit('//   - If Tinner > 1, then nt_in_per_wt == (32 * simd_width) / Tinner')
        k.emit('//   - nt_in is a mutliple of nt_in_per_wt')
        k.emit('//   - nt_in is a multiple of (32 * simd_width)')
        k.emit('//   - total warps (B*W) is a multiple of ndm_out_per_wt')
        k.emit('//')
        k.emit('// Note: the PfWeightLayout parameters (ndm_wt,nt_wt,P,F) are given by:')
        k.emit('//   - ndm_wt = (B*W) / ndm_out_per_wt')
        k.emit('//   - nt_wt = nt_in / nt_in_pwer_wt')
        k.emit('//   - P = 3*log2(E) + 1')
        k.emit('//   - F = frequency_subbands.F')
        k.emit('//')
        k.emit('// FIXME assuming 32 threads/block and 16 threadblocks/SM for now')
        k.emit('__global__ void __launch_bounds__(32,16)')
        k.emit(f'{self.kernel_name}(const void *in_, void *out_max_, uint *out_argmax, const void *wt_, void *pstate_, uint nt_in, uint ndm_out_per_wt, uint nt_in_per_wt)')
        k.emit('{')
        k.emit(f'constexpr int M = {self.M};')
        k.emit(f'constexpr int Dout = {self.Dout};')
        k.emit(f'constexpr int Dcore = {self.Dcore};')
        k.emit(f'constexpr int Tinner = {self.Tinner};')
        k.emit(f'constexpr int wt_touter_stride32 = {utils.xdiv(self.wt_touter_byte_stride,4)};')

        # Line 'constexpr int PW32 = xx;' will be spliced in here (pstate 32-bit registers per warp)
        self.kpw32 = k.splice()

        k.emit()
        k.emit(f'const {dt32} *in = (const {dt32} *) in_;')
        k.emit(f'const {dt32} *wt = (const {dt32} *) wt_;')
        k.emit(f'{dt32} *out_max = ({dt32} *) out_max_;')
        k.emit(f'{dt32} *pstate = ({dt32} *) pstate_;')
        k.emit()

        nt_out = self._idiv('nt_in', Dout)
        nt_in32 = self._idiv('nt_in', SW)
        nt_out32 = self._idiv('nt_in', Dout*SW)

        k.emit(f'// FIXME could optimize out integer divisions')
        k.emit(f'uint warp = blockIdx.x * blockDim.x + threadIdx.y;')
        k.emit(f'uint dm_w = warp / ndm_out_per_wt;         // dm index in weight array')
        k.emit(f'uint Touter = nt_in / (Tinner * nt_in_per_wt);  // see PfWeightLayout')
        k.emit()
        
        k.emit(f'// Add per-warp pointer offsets, but not per-lane offsets')
        k.emit(f'in += warp * M * {nt_in32};                    // shape (B*W, M, nt_in)')
        k.emit(f'out_max += warp * {nt_out32};                  // shape (B*W, nt_in/Dout)')
        k.emit(f'out_argmax += warp * {nt_out};                 // shape (B*W, nt_in/Dout)')
        k.emit(f'wt += dm_w * Touter * wt_touter_stride32;  // shape (ndm_wt,Touter,...)')
        k.emit(f'pstate += warp * PW32;                       // shape (B*W, PW32)')    
        k.emit()

        if self.E > 1:
            k.emit(f'{dt32} pf_a = {self.dtype.from_float("0.5f")};')
            k.emit()

        # PfWeightReader.top() is currently a placeholder that does not emit any code.
        self.pf_weight_reader.top(k, 'wt')
        
        # Code to load ring buffer pstate will be spliced in here.
        self.kps = k.splice()

        k.emit()
        k.emit(f'for (uint tin = 0; tin < nt_in; tin += {32*SW}) {{')

        for m in range(M):
            t = f'({m} * {nt_in32})' if (m > 1) else nt_in32
            t = f'in[{t} + threadIdx.x]' if (m > 0) else 'in[threadIdx.x]'

            k.emit()
            k.emit(f'// Read {m=} from global memory')
            self.process_pf_input(k, t, m)

        # Bottom of tin-loop 1: process pf_output.
        self.pf_output.apply_outer(k, 'out_max', 'out_argmax', 'tin', 'nt_in')

        # bottom of tin-loop 2: advance weight_reader.
        self.pf_weight_reader.bottom(k, 'tin', 'nt_in_per_wt')
        
        # Bottom of tin-loop 3: advance ringbuf.
        self.rb.advance_outer(k)
        
        # Bottom of tin-loop 4: advance input pointer.
        k.emit()
        k.emit('// Advance input pointer.')
        k.emit('in += 32;')
        k.emit('}  // end of tin loop')

        # Ring buffer gymnastics. First, emit code at bottom of kernel to save pstate.
        self.rb.finalize(k, 'pstate')

        # Second (after calling finalize()), emit definition of PW32 at top of kernel (note 'kpw32' here)
        self.PW32 = self.rb.get_n32_per_warp()
        self.kpw32.emit(f'constexpr int PW32 = {self.PW32};  // 32-bit pstate registers per warp')

        # Third, emit code near top of kernel to load pstate (note 'kps' here)
        self.rb.initialize(self.kps, 'pstate')
        
        k.emit('}  // end of cuda kernel')
        k.emit()

        # Emit registration boilerplate for GpuPeakFindingKernel2.
        self._emit_registration_boilerplate(k)


    def _emit_registration_boilerplate(self, k):
        """Emit C++ boilerplate to register the kernel when the library is loaded."""

        fs = self.frequency_subbands
        wl = self.weight_layout
        sb_counts = ', '.join(str(int(x)) for x in fs.subband_counts)
        m_to_f = ', '.join(str(int(f)) for f,d in fs.m_to_fd)
        m_to_d = ', '.join(str(int(d)) for f,d in fs.m_to_fd)
        f_to_ilo = ', '.join(str(int(ilo)) for ilo,ihi in fs.f_to_irange)
        f_to_ihi = ', '.join(str(int(ihi)) for ilo,ihi in fs.f_to_irange)
        
        k.emit('\n// Boilerplate to register the kernel when the library is loaded.')
        k.emit('namespace {')
        k.emit('struct register_hack {')
        k.emit('register_hack() {')
        k.emit('GpuPeakFindingKernel2::RegistryKey k;')
        k.emit(f'k.dtype = ksgpu::Dtype::native<{self.dtype.scalar}>();')
        k.emit(f'k.subband_counts = {{ {sb_counts} }};')
        k.emit(f'k.Tinner = {self.Tinner};')
        k.emit(f'k.Dout = {self.Dout};')
        k.emit(f'k.E = {self.E};')
        k.emit()
        k.emit('GpuPeakFindingKernel2::RegistryValue v;')
        k.emit(f'v.cuda_kernel = {self.kernel_name};')
        k.emit(f'v.Dcore = {self.Dcore};')
        k.emit(f'v.PW32 = {self.PW32};')
        k.emit()
        k.emit(f'v.pf_weight_layout.dtype = ksgpu::Dtype::native<{self.dtype.scalar}>();')
        k.emit(f'v.pf_weight_layout.F = {fs.F};')
        k.emit(f'v.pf_weight_layout.P = {self.P};')
        k.emit(f'v.pf_weight_layout.Pouter = {wl.Pouter};')
        k.emit(f'v.pf_weight_layout.Pinner = {wl.Pinner};')
        k.emit(f'v.pf_weight_layout.Tinner = {self.Tinner};')
        k.emit(f'v.pf_weight_layout.touter_byte_stride = {wl.touter_byte_stride};')
        k.emit(f'v.pf_weight_layout.validate();  // throws an exception if anything is wrong')
        k.emit()
        k.emit('// Checks consistency of python/C++ FrequencySubbands')
        k.emit(f'FrequencySubbands fs({{ {sb_counts} }});')
        k.emit(f'xassert_eq(fs.F, {fs.F});')
        k.emit(f'xassert_eq(fs.M, {fs.M});')
        k.emit(f'xassert(vec_equal(fs.m_to_f, {{ {m_to_f} }}));')
        k.emit(f'xassert(vec_equal(fs.m_to_d, {{ {m_to_d} }}));')
        k.emit(f'xassert(vec_equal(fs.f_to_ilo, {{ {f_to_ilo} }}));')
        k.emit(f'xassert(vec_equal(fs.f_to_ihi, {{ {f_to_ihi} }}));')
        k.emit()
        k.emit('bool debug = false;')
        k.emit('GpuPeakFindingKernel2::registry().add(k, v, debug);')
        k.emit('} // register_hack constructor')
        k.emit('}; // struct register_hack')
        k.emit('register_hack hack;')
        k.emit('} // anonymous namespace')
        k.emit()
        k.emit('}   // namespace pirate')

        
    def process_pf_input(self, k, expr, m):
        """Called in main loop of emit_kernel()."""

        M = self.M
        Mpad = utils.align_up(M, self.Dcore)
        
        b = tuple(('t',i) for i in range(self.pfx_nb))
        l = tuple(('t',i+self.pfx_nb) for i in range(self.pfx_nl))
        var = self.pfx_name(m, 0, b, l)
        
        k.emit(f'{self.dt32} {var} = {expr};')        
        self.pfx_register_ready(k, m, 0, b, l)

        if (m == M-1) and (M < Mpad):
            k.emit()
            k.emit(f'// FIXME: creating dummy pfx registers for M <= m < Mpad, where {M=} and {Mpad=}.')
            k.emit(f'// FIXME: this is suboptimal but convenient!')
            
            for mm in range(M, Mpad):
                dummy = self.pfx_name(mm, 0, b, l)
                k.emit(f'{self.dt32} {dummy} = {var};')

            for mm in range(M, Mpad):
                self.pfx_register_ready(k, mm, 0, b, l)


    def _is_si_pair(self, x):
        return isinstance(x,tuple) and (len(x)==2) and isinstance(x[0],str) and isinstance(x[1],int)

    def _assert_is_si_tuple(self, x, expected_length):
        """Helper for pfx_name()."""
        if (not isinstance(x,tuple)) or (len(x) != expected_length) or any(not self._is_si_pair(y) for y in x):
            raise RuntimeError(f'Expected length-{expected_length} tuple of (str,int) pairs, got: {x}')

    def _si_tuple_str(self, x):
        """Helper for pfx_name()."""
        return ('_' + ''.join(f'{s}{i}' for s,i in x)) if (len(x) > 0) else ''

    def pfx_name(self, m, t, b, l):
        """Helper for pfx_register_ready() and friends."""
        assert isinstance(m,int) and isinstance(t,int)
        self._assert_is_si_tuple(b, self.pfx_nb)
        self._assert_is_si_tuple(l, self.pfx_nl)
        return f'pfx_m{m}t{t}{self._si_tuple_str(b)}{self._si_tuple_str(l)}'

        
    def pfx_register_ready(self, k, m, t, b, l):
        dt32, M, Dcore = self.dt32, self.M, self.Dcore

        # Transpose lanes?
        
        for i in range(self.pfx_nl):
            if l[i][0] != 't':
                continue
            
            mbit = (1 << i)
            tbit = (1 << l[i][1])
            if (m & mbit) == 0:
                return

            lnew = l[:i] + (('m',i),) + l[(i+1):]
            iname0 = self.pfx_name(m-mbit, t, b, l)
            iname1 = self.pfx_name(m, t, b, l)
            oname0 = self.pfx_name(m-mbit, t, b, lnew)
            oname1 = self.pfx_name(m-mbit, t+tbit, b, lnew)

            k.emit()
            k.emit(f'// Warp transpose (bit {i})')
            k.emit(f'// Inputs: {iname0}, {iname1}')
            k.emit(f'// Outputs: {oname0}, {oname1}')

            tmp1, tmp2 = k.get_name('tmp', 2)
            k.emit(f'{dt32} {tmp1} = (threadIdx.x & {1<<i}) ? {iname0} : {iname1};')
            k.emit(f'{dt32} {tmp2} = __shfl_xor_sync(~0u, {tmp1}, {1<<i});')
            k.emit(f'{dt32} {oname0} = (threadIdx.x & {1<<i}) ? {tmp2} : {iname0};')
            k.emit(f'{dt32} {oname1} = (threadIdx.x & {1<<i}) ? {iname1} : {tmp2};')

            self.pfx_register_ready(k, m-mbit, t, b, lnew)
            self.pfx_register_ready(k, m-mbit, t+tbit, b, lnew)
            return

        # Transpose simd bit?

        if (self.pfx_nb == 1) and (b[0] == ('t',0)):
            mbit = (1 << self.pfx_nl)
            if (m & mbit) == 0:
                return

            bnew = (('m',self.pfx_nl),)
            iname0 = self.pfx_name(m-mbit, t, b, l)
            iname1 = self.pfx_name(m, t, b, l)
            oname0 = self.pfx_name(m-mbit, t, bnew, l)
            oname1 = self.pfx_name(m-mbit, t+1, bnew, l)

            k.emit()
            k.emit(f'// Local (__half2) transpose')
            k.emit(f'// Inputs: {iname0}, {iname1}')
            k.emit(f'// Outputs: {oname0}, {oname1}')

            k.emit(f'{dt32} {oname0} = __lows2half2({iname0}, {iname1});')
            k.emit(f'{dt32} {oname1} = __highs2half2({iname0}, {iname1});')
            
            self.pfx_register_ready(k, m-mbit, t, bnew, l)
            self.pfx_register_ready(k, m-mbit, t+1, bnew, l)
            return

        # If we get here, then register should be "all ms".
        assert (m % Dcore) == 0
        assert b == tuple(('m',i+self.pfx_nl) for i in range(self.pfx_nb))
        assert l == tuple(('m',i) for i in range(self.pfx_nl))

        if (t == Dcore-1):
            k.emit()
            k.emit(f'// Transpose complete -- now ready to run peak-finders for {m} <= m < {m+Dcore}')
            k.emit(f'// First, some renames for readability.')

            for tt in range(Dcore):
                k.emit(f'{dt32} {self.pfy_name(1,m,tt)} = {self.pfx_name(m,tt,b,l)};')

            self.pfy_registers_ready(k, m)


    def pfy_name(self, W, m, t):
        """Helper for pfy_registers_ready() and friends."""
        return f'pfy{W}_m{m}_t{t}' if (t >= 0) else f'pfy{W}_m{m}_tn{-t}'

    
    def _get_pfy(self, k, W, m, t, allow_ringbuf=True):
        """Helper for pfy_registers_ready()."""

        dt32, Dcore, Minner = self.dt32, self.Dcore, self.Minner
        
        # Convenient shorthand.
        pfy = lambda W,t: self.pfy_name(W,m,t)
        check = lambda W,t: ((W,m,t) in self.pfys_held)

        if check(W,t):
            return
        
        if (W > 1) and check(W//2,t) and check(W//2,t+W//2):
            k.emit(f'{dt32} {pfy(W,t)} = {pfy(W//2,t)} + {pfy(W//2,t+W//2)};')
            self.pfys_held.add((W,m,t))
            return
                    
        for l in range(32):
            if allow_ringbuf and check(W,t+l*Dcore):
                k.emit(f'// Set {pfy(W,t)} = ringbuf.advance({pfy(W,t+l*Dcore)}, {l*Minner})')
                k.emit(f'{dt32} {pfy(W,t)};')
                self.rb.advance(k, pfy(W,t+l*Dcore), l*Minner, dst=pfy(W,t))
                self.pfys_held.add((W,m,t))
                return

        raise RuntimeError(f'Internal error: PeakFinder._get_pfy({W=}, {m=}, {t=}, {allow_ringbuf=}) failed')

    
    def _read_weights(self, k, m, p):
        """
        Called in pfy_registers_ready(), to "prefetch" weights.
        The weights are applied in pfz_register_ready().
        """

        Dcore, Minner, Pinner = self.Dcore, self.Minner, self.Pinner
        assert (m % Dcore) == 0
        
        if self.dtype == 'float':
            assert Pinner == 1
            assert Dcore == Minner
            mouter = utils.xdiv(m, Minner)
            self.pf_weight_reader.read_weights(k, f'pfw_m{m}_p{p}', mouter, p)
        
        elif self.dtype == '__half' and ((p % 2) == 0):
            assert Pinner == 2
            assert Dcore == 2*Minner
            mouter = utils.xdiv(m, Minner)
            pouter = utils.xdiv(p, Pinner)
            self.pf_weight_reader.read_weights(k, f'pfw_m{m}_p{p}', mouter, pouter)
            self.pf_weight_reader.read_weights(k, f'pfw_m{m+Minner}_p{p}', mouter+1, pouter)
                
        elif self.dtype != '__half':
            raise RuntimeError('should never get here')

    
    def _absorb_pfz(self, k, var, m, p, t):
        """
        Helper for pfy_registers_ready().
        Variables named 'pfz_m{m}_p{p}' store max-values (either float or __half2)
        Variables named 'pfiz_m{m}_p{p}' store "mini-tokens" 0 <= t < Dcore.
        Mini-tokens are always declared 'uint', but are secretly either u32 or u16x2.
        """
        
        pfz = f'pfz_m{m}_p{p}'
        pfiz = f'pfiz_m{m}_p{p}'
        assert 0 <= t < self.Dcore

        if (m,p) not in self.pfz_decl:
            k.emit(f'{self.dt32} {pfz} = {var};')
            k.emit(f'uint {pfiz} = {t};')
            self.pfz_decl.add((m,p))
        
        elif self.dtype == 'float':
            k.emit(f'{pfiz} = ({pfz} < {var}) ? {t} : {pfiz};')
            k.emit(f'{pfz} = fmaxf({pfz}, {var});')
        
        elif self.dtype == '__half':
            cmp1, cmp2 = k.get_name('cmp', 2)
            k.emit(f'__half2 {cmp1} = __hle2({pfz}, {var});')
            k.emit(f'uint {cmp2} = *reinterpret_cast<uint*>(&{cmp1});  // __half2 -> uint')
            k.emit(f'{pfiz} = ({cmp2} & 0x{(t|(t<<16)):0x}) | (~{cmp2} & {pfiz});  // compiles to lop3')
            k.emit(f'{pfz} = __hmax2({pfz}, {var});')
        
        else:
            raise RuntimeError('should never get here')
            
        
    def pfy_registers_ready(self, k, m):
        dt32, E, Dcore, Minner = self.dt32, self.E, self.Dcore, self.Minner
        assert m % Dcore == 0

        # Convenient shorthand.
        pfy = lambda W,t: self.pfy_name(W,m,t)

        # Caller has ensured that these pfy registers are defined.
        for t in range(Dcore):
            self.pfys_held.add((1,m,t))

        self._read_weights(k, m, p=0)
        
        k.emit()
        k.emit(f'// Compute p=0 peak-finding kernel')
        for t in range(0, self.Dcore):
            self._absorb_pfz(k, pfy(1,t), m, 0, t)

        self.pfz_register_ready(k, m, 0)

        # Loop over W = 1, 2, 4, ..., (E//2).
        for lgW in range(utils.integer_log2(E)):
            W = 2**lgW

            # tends = "we want to process width-W kernels which end at these times"
            # tstarts = "we will need width-W pfy-registers which start at these times"
            # t0 = "when computing time indices in argmax tokens, use (tend-t0)"
            
            tends = list(range(W,Dcore+W,W)) if (W < Dcore) else [Dcore]
            tstarts = sorted(set(tend-i*W for tend in tends for i in range(1,5)))
            t0 = tends[0]

            for t in tstarts:
                self._get_pfy(k, W, m, t)
                
            self._read_weights(k, m, 3*lgW+1)

            k.emit()
            k.emit(f'// Compute p={3*lgW+1} peak-finding kernel.')
            for tend in tends:
                self._get_pfy(k, 2*W, m, tend-2*W, allow_ringbuf=False)
                self._absorb_pfz(k, pfy(2*W,tend-2*W), m, 3*lgW+1, tend-t0)
            self.pfz_register_ready(k, m, 3*lgW+1)
            
            self._read_weights(k, m, 3*lgW+2)
            
            k.emit()
            k.emit(f'// Compute p={3*lgW+2} peak-finding kernel.')
            for tend in tends:
                tmp = k.get_name('tmp')
                k.emit(f'{dt32} {tmp} = {pfy(W,tend-2*W)} + pf_a * ({pfy(W,tend-3*W)} + {pfy(W,tend-W)});  // p={3*lgW+2}')
                self._absorb_pfz(k, tmp, m, 3*lgW+2, tend-t0)
            self.pfz_register_ready(k, m, 3*lgW+2)

            self._read_weights(k, m, 3*lgW+3)
            self._get_pfy(k, 2*W, m, tends[0]-3*W, allow_ringbuf=False)    # stray

            k.emit()
            k.emit(f'// Compute p={3*lgW+3} peak-finding kernel.')
            for tend in tends:
                tmp2 = k.get_name('tmp')
                k.emit(f'{dt32} {tmp2} = {pfy(2*W,tend-3*W)} + pf_a * ({pfy(W,tend-4*W)} + {pfy(W,tend-W)});  // p={3*lgW+3}')
                self._absorb_pfz(k, tmp2, m, 3*lgW+3, tend-t0)
            self.pfz_register_ready(k, m, 3*lgW+3)


    def _tokenize_mp(self, k, m, p):
        """
        Recall that tokens are formatted as (t) | (p << 8) | (d << 14) | (f0 << 20) | (f1 << 26).
        This function returns everything after the (t), as an immediate (not a varname).
        """

        # Token = (t) | (p << 8) | (d << 14) | (flo << 20) | (fhi << 26);
        mm = min(m, self.M-1)
        f_ix, d = self.frequency_subbands.m_to_fd[mm]
        f_lo, f_hi = self.frequency_subbands.f_to_irange[f_ix]
        token = (p << 8) | (d << 14) | (f_lo << 20) | (f_hi << 26)
        token = f'0x{token:x}U'
        k.emit(f'// Note: ({m=},{p=}) tokenizes to {token}')
        return token

    
    def pfz_register_ready(self, k, m, p):
        """
        Called when the following vars are ready:

          - pfz_m{m}_p{p}: stores max-values (either float or __half2)

          - pfiz_m{m}_p{p}: store "mini-tokens" 0 <= t < Dcore.
            Mini-tokens are always declared 'uint', but are secretly either u32 or u16x2.

        Recall that tokens are formatted as (t) | (p << 8) | (d << 14) | (f0 << 20) | (f1 << 26).
        To convert a minitoken to a token, we do something like this:

            token = minitoken | (threadIdx.x & (Dout-Dcore)) | _tokenize_mp(k,m,p);
        """

        Minner, P = self.Minner, self.P
        
        k.emit()
        k.emit(f'// pfz_register_ready({m=}, {p=}) called.')

        if self.dtype == 'float':
            k.emit(f'pfz_m{m}_p{p} *= pfw_m{m}_p{p};')
            token_mp = self._tokenize_mp(k, m, p)
            k.emit(f'uint token_m{m}_p{p} = pfiz_m{m}_p{p} | (threadIdx.x & (Dout-Dcore)) | {token_mp};')
            self.pf_output.apply_inner(k, f'pfz_m{m}_p{p}', [ f'token_m{m}_p{p}' ])

        elif (self.dtype == '__half') and ((p % 2) == 0) and (p < (P-1)):
            k.emit(f'// This is a no-op (need to wait for p={P+1}).')

        elif (self.dtype == '__half') and ((p % 2) == 0) and (p == (P-1)):
            k.emit(f'// Creating dummpy pfz registers for {m=}, p={P}')
            k.emit(f'// FIXME: this is suboptimal but convenient!')
            k.emit(f'__half2 pfz_m{m}_p{P} = pfz_m{m}_p{P-1};')
            k.emit(f'uint pfiz_m{m}_p{P} = pfiz_m{m}_p{P-1};')            
            self.pfz_register_ready(k, m, P)

        elif (self.dtype == '__half') and (p % 2):
            m0, m1 = m, (m+Minner)
            p0, p1 = (p-1), p
            pfz0, pfz1 = f'pfz_m{m0}_p{p0}', f'pfz_m{m0}_p{p1}'
            pfu0, pfu1 = f'pfu_m{m0}_p{p0}', f'pfu_m{m1}_p{p0}'

            k.emit(f'// Local transpose')
            k.emit(f'// Input: {pfz0}, {pfz1}  (simd <-> (m{m0},m{m1}), reg <-> (p{p0},p{p1})')
            k.emit(f'// Output: {pfu0}, {pfu1} (simd <-> (p{p0},p{p1}), reg <-> (m{m0},m{m1})')
            k.emit(f'__half2 {pfu0} = __lows2half2({pfz0}, {pfz1});')
            k.emit(f'__half2 {pfu1} = __highs2half2({pfz0}, {pfz1});')

            k.emit(f'{pfu0} *= pfw_m{m0}_p{p};')
            k.emit(f'{pfu1} *= pfw_m{m1}_p{p};')
                    
            token_m0_p0 = self._tokenize_mp(k, m0, p0)
            token_m0_p1 = self._tokenize_mp(k, m0, p1)
            token_m1_p0 = self._tokenize_mp(k, m1, p0)
            token_m1_p1 = self._tokenize_mp(k, m1, p1)
            
            k.emit(f'uint token_m0_p0 = (pfiz_m{m0}_p{p0} & 0x0000ffffu) | ((threadIdx.x << 1) & (Dout-Dcore)) | {token_m0_p0};')
            k.emit(f'uint token_m0_p1 = (pfiz_m{m0}_p{p1} & 0x0000ffffu) | ((threadIdx.x << 1) & (Dout-Dcore)) | {token_m0_p1};')
            k.emit(f'uint token_m1_p0 = (pfiz_m{m0}_p{p0} & 0xffff0000u) | ((threadIdx.x << 1) & (Dout-Dcore)) | {token_m1_p0};')
            k.emit(f'uint token_m1_p1 = (pfiz_m{m0}_p{p1} & 0xffff0000u) | ((threadIdx.x << 1) & (Dout-Dcore)) | {token_m1_p1};')
            
            self.pf_output.apply_inner(k, pfu0, [ f'token_m{m0}_p{p0}', f'token_m{m0}_p{p1}' ])
            self.pf_output.apply_inner(k, pfu1, [ f'token_m{m1}_p{p0}', f'token_m{m1}_p{p1}' ])

        else:
            raise RuntimeError('should never get here')
        
    
    @classmethod
    def write_kernel(cls, filename):
        """Called from 'autogenerate_kernel.py' in the toplevel pirate directory."""
        
        basename = os.path.basename(filename)

        # Typical basename: pf2_fp32_f11_f6_f3_f1_E16_Dcore8_Dout16_Tinner1.cu
        m = re.fullmatch(r'pf2_(fp\d+)_((?:f\d+_)*f\d+)_E(\d+)_Dcore(\d+)_Dout(\d+)_Tinner(\d+)\.cu', basename)
        if not m:
            raise RuntimeError(f"Couldn't match filename '{filename}'")
        
        dtype = Dtype(m.group(1))
        frequency_subbands = FrequencySubbands.from_fstr(m.group(2))
        E, Dcore, Dout, Tinner = int(m.group(3)), int(m.group(4)), int(m.group(5)), int(m.group(6))

        pf_kernel = cls(dtype, frequency_subbands, E, Dcore, Dout, Tinner)

        if pf_kernel.kernel_basename != basename:
            raise RuntimeError("PfKernel2.write_test_kernel(): internal error: expected "
                               + f" {pf_kernel.kernel_basename=} and {basename=} to be equal")
                
        k = Kernel()
        pf_kernel.emit_kernel(k)

        with open(filename,'w') as f:
            with utils.clang_formatter(f) as ff:
                k.write(ff)

        

####################################################################################################


class PfWeightLayout:
    def __init__(self, frequency_subbands, dtype, P, Tinner):
        """
        PfWeightLayout: helper class for peak-finder.
        
        The W-array in global memory
        ----------------------------
        
        The W-array is a logical 4-d array with shape (ndm_wt,nt_wt,P,F) parameterized by:
        
          - ndm_wt = number of coarse DMs in weights array
          - nt_wt = number of coarse time samples in weights array
          - P = number of peak-finding profiles
          - F = number of frequency subbands F

        Before describing the global memory layout, a few more definitions:

          SW = 32 / sizeof(T)         "simd width"
          Tinner = max(32*SW/nt_in_per_wt, 1)   see (*) below
          Pinner = SW                  see (**) below

        Then, we split P,nt_wt into "outer" and "inner" parts:
        
          Pouter = ceil(P / Pinner)   where Pinner = SW (**)
          Touter = nt_wt / Tinner

        The W-array global memory layout can be described as either a 6-d or a 5-d array:
        
           dtype          W[ndm_wt,Touter,Pouter,F,Tinner,Pinner]
           dtype*Pinnner  W[ndm_wt,Touter,Pouter,F,Tinner]

        Important note: we always pad so that the 'Touter' stride is 128-byte aligned!
        (See "self.touter_stride" below.)

        (*) Tinner is the number of W-array t-indices per iteration of the "outer time loop"
            in the larger kernel. Each iteration of this loop processes 128 / sizeof(dtype)
            "tree" time samples.
        
        (**) Pinner is an "innermost width" used for weights in the peak-finding kernel. Currently,
             it is always equal to the simd_width SW. However, in a future update, I may implement
             a shared-memory code path (see FIXME below) in which Pinner = 2*SW.
        
        Constructor args
        ----------------

          - frequency_subbands: instance of class FrequencySubbands
        
          - dtype: either Dtype instance or string
        
          - P: number of peak-finding kernels (see toplevel kernel).
        
          - Tinner: defined as max(32*SW/nt_in_per_wt, 1), see above for discussion.
        """

        assert isinstance(frequency_subbands, FrequencySubbands)
        assert utils.is_power_of_two(Tinner)
        assert Tinner <= 32
        assert P > 0

        self.frequency_subbands = frequency_subbands
        self.dtype = dtype = Dtype(dtype)
        self.F = frequency_subbands.F
        self.Tinner = Tinner
        self.P = P
        
        # See docstring for definitions of these quantities. Note that for now, Pinner
        # is equal to the simd width, but this may change in the future.
        self.Pinner = dtype.simd_width
        self.Pouter = (self.P + self.Pinner - 1) // self.Pinner

        # The weights array is stored with a non-contiguous (128-byte) aligned touter-stride (see docstring).
        self.unpadded_byte_stride = self.Pouter * self.F * Tinner * self.Pinner * utils.xdiv(dtype.nbits,8)
        self.touter_byte_stride = (self.unpadded_byte_stride + 127) & ~127   # round up to multiple of 128
        

####################################################################################################


class PfWeightReader:
    def __init__(self, frequency_subbands, dtype, Dcore, P, Tinner):
        """
        Generated code looks like this
        ------------------------------

          constexpr int SW = 128 / sizeof(dtype);  // simd width
        
          // Initialization of input pointer is not supplied by PfWeightReader.
          // 'wp' is a per-warp pointer to shape (Touter,Pouter,F,Tinner,Pinner/SW),
          // where the 'touter' stride is 128-byte aligned. The pointer is "owned"
          // by the PfWeightReader class, and will be incremented as data is read
          // from global memory.
        
          T32 *wp = ...;
          pfw_reader.top('wp');
        
          // Loop over t-values is not supplied by PfOutput2.
          for (uint tin = 0; tin < nt_in; t += 32*SW) {

              // Outer "unrolled" loop over 0 <= mouter < Mouter.
              // Inner "unrolled" loop over 0 <= pouter < Pouter.
              w = pfw_reader.read_weights('pfw_m0_p0', mouter=0, pouter=0)
              w = pfw_reader.read_weights('pfw_m0_p1, mouter=0, pouter=1)
                // ...
              w = pfw_reader.read_weights(f'pfw_m{Minner*(Mouter-1)}_p{Pouter-1}',
                                          mouter=Mouter-1, pouter=Pouter-1)
        
              pfw_reader.bottom('tin', 'nt_in')
          }
        """

        self.dtype = dtype = Dtype(dtype)
        self.weight_layout = PfWeightLayout(frequency_subbands, dtype, P, Tinner)
        self.frequency_subbands = frequency_subbands
        self.Tinner = Tinner
        self.Dcore = Dcore
        self.P = P

        self.dt32 = dtype.simd32
        self.SW = dtype.simd_width
        self.Pouter = self.weight_layout.Pouter
        self.Pinner = self.weight_layout.Pinner
        self.M = frequency_subbands.M
        self.F = frequency_subbands.F

        assert utils.is_power_of_two(Dcore)
        assert utils.is_power_of_two(Tinner)
        assert (Dcore) >= (self.SW)
        assert (Dcore * Tinner) <= (32 * self.SW)
        assert P > 0
        
        # See docstring for definitions of these quantities. Note that for now, Pinner
        # is equal to the simd width, but this may change in the future (see FIXME below).
        self.Minner = Minner = utils.xdiv(Dcore, self.SW)
        self.Mouter = Mouter = (self.M + Minner - 1) // Minner

        # Typical kernel name: pf_weight_reader_test_fp32_f11_f6_f3_f1_Dcore8_P13_Tinner2
        self.test_kernel_name = f'pf_weight_reader_test_{dtype.fname}_{frequency_subbands.fstr}_Dcore{Dcore}_P{P}_Tinner{Tinner}'
        self.test_kernel_basename = self.test_kernel_name + '.cu'

        # Throughout 'class PfWeightReader', a capitalized index 0 <= I < Pouter*F*Tinner
        # denotes a "flattened" index triple (pouter, f, tinner). Such an index I can be
        # viewed as an offset relative to the 'wp' pointer (see docstring), and (I >> 5)
        # corresponds to a cache line.

        # 'pf_I0' is the mapping (mouter,minner) -> I, for pouter=tinner=0.
        self.pf_I0 = np.zeros((Mouter,Minner), dtype=int)
        for mouter in range(Mouter):
            for minner in range(Minner):
                m = min(mouter*Minner + minner, self.M-1)
                f = frequency_subbands.m_to_fd[m][0]
                self.pf_I0[mouter, minner] = f * Tinner

        # pf_Imin = min(pf_I0) over all lanes, i.e. all (minner,tinner) pairs.
        self.pf_Imin = np.min(self.pf_I0, axis=1)
        self.pf_Imax = np.max(self.pf_I0, axis=1) + (Tinner - 1)

        # Dict (cache line index I>>5) -> (wcl string varname).
        # This gets populated as read_weights() is called.
        self.wcl_cache = { }

        self.top_called = False
        self.expected_mouter = 0
        self.expected_pouter = 0
        self.bottom_called = False
        
        # FIXME 1: shared memory
        #  - less global memory bandwidth
        #  - faster than warp shuffle, if 64-bit loads are used, on some architectures
        #  - Pinner may change to (2 * simd_width)
        #  - API change: read_weights() can now return two T32s
        #
        # FIXME 2: register limit
        #  - Use Belady's algorithm
        #
        # FIXME 3: if Tinner=1 then test whether re-reading is really necessary
        #
        # The optimal interface would specify a register limit, a shared memory limit,
        # and let the constructor choose the strategy!
        #
        # FIXME 4: dynamic programming
        
        
    def top(self, k, wp):
        """Placeholder for future expansion."""
        
        assert not self.top_called
        self.top_called = True
        self.wp = wp


    def _read_wcl(self, k, Icl):
        if Icl in self.wcl_cache:
            w = self.wcl_cache[Icl]
            k.emit(f"// At this point in the code, '{w}' contains {self.wp}[{32*Icl}:{32*Icl+32}]")
            return w

        wcl = k.get_name('pf_wcl')
        k.emit(f"{self.dt32} {wcl} = {self.wp}[{32*Icl} + (threadIdx.x & 0x1f)]; // {self.wp}[{32*Icl}:{32*Icl+32}]")
        self.wcl_cache[Icl] = wcl
        return wcl

    
    def read_weights(self, k, dst, mouter, pouter, declare_dst=True):
        assert self.top_called
        assert not self.bottom_called

        if (mouter, pouter) != (self.expected_mouter, self.expected_pouter):
            raise RuntimeError(f'PfWeightReader.read_weights(): {(mouter,pouter)=}, expected={(self.expected_mouter,self.expected_pouter)}')

        self.expected_mouter = (mouter) if (pouter < self.Pouter-1) else (mouter+1)
        self.expected_pouter = (pouter+1) if (pouter < self.Pouter-1) else 0
        
        wp, F, Tinner = self.wp, self.F, self.Tinner
        k.emit(f'// PfWeightReader.read_weights({dst=}, {mouter=}, {pouter=}): start.')

        if pouter == 0:
            self._init_pf_I(k, mouter)

        dI = pouter * F * Tinner
        Imin = int(self.pf_Imin[mouter]) + dI
        Imax = int(self.pf_Imax[mouter]) + dI
        Istr = f'pf_I + {dI}' if (dI > 0) else 'pf_I'

        # Very important assert -- our algorithm depends on this!
        assert np.all(Imax < Imin + 32)

        k.emit(f'// We want to load {wp}[{Istr}] on each thread, where {Imin} <= ({Istr}) <= {Imax}.')
        wcl = self._read_wcl(k, Imin >> 5)

        if (Imin >> 5) != (Imax >> 5):
            wcl2 = self._read_wcl(k, Imax >> 5)
            wrap = k.get_name('wrap')
            k.emit(f'// Wrapped {wp}[{Imin}:{Imin+32}]')
            k.emit(f'{self.dt32} {wrap} = ((threadIdx.x & 0x1f) >= {Imin & 0x1f}) ? {wcl} : {wcl2};')
            wcl = wrap

        decl = f'{self.dt32} ' if declare_dst else ''
        k.emit(f'{decl}{dst} = __shfl_sync(~0u, {wcl}, {Istr});')
        k.emit(f'// PfWeightReader.read_weights({dst=}, {mouter=}, {pouter=}): end')


    def _init_pf_I(self, k, mouter):
        """Helper called by read_weights()."""
        
        Minner, Tinner = self.Minner, self.Tinner
        
        Mbits = utils.integer_log2(Minner)
        Tbits = utils.integer_log2(Tinner)
        minner = f'(threadIdx.x & {Minner-1})' if (Minner > 1) else '0'
        tinner = f'((threadIdx.x & 0x1f) >> {5-Tbits})' if (Tinner > 1) else '0'
        
        k.emit()
        k.emit(f'// In this part, we have {Minner=}, {Tinner=}, and the following mapping between')
        k.emit(f'// lanes and (minner,tinner) pairs:')
        k.emit(f'//    {Mbits} lane bits <-> minner')
        k.emit(f'//    {5-Mbits-Tbits} lane bits <-> spectator t-indices')
        k.emit(f'//    {Tbits} lane bits <-> tinner')
        k.emit(f'//')
        k.emit(f'// Therefore, {minner = } and {tinner = }')
        k.emit(f'//')
        k.emit(f'// Compute pf_I: the I-index for (mouter,pouter)=({mouter},0), and (minner,tinner)')
        k.emit(f'// defined by the laneId. For tinner=0, this is described by the following lookup')
        k.emit(f'// table (minner) -> (pf_I): {list(map(int,self.pf_I0[mouter,:]))}')
        k.emit('//')
        k.emit('// FIXME: placeholder algorithm for computing pf_I (dynamic programming is best!).')

        decl = 'int ' if (mouter == 0) else ''
        k.emit(f'{decl}pf_I = {int(self.pf_I0[mouter,0])};')

        for m in range(1, Minner):
            if self.pf_I0[mouter,m] != self.pf_I0[mouter,m-1]:
                k.emit(f'pf_I = ({minner} < {m}) ? pf_I : {int(self.pf_I0[mouter,m])};')

        if Tinner != 1:
            k.emit(f'pf_I += {tinner};')
        else:
            k.emit(f'// since Tinner=1, no need for "pf_I += tinner;"')

    
    def bottom(self, k, tin, nt_in_per_wt):
        """The 'tin', 'nt_in_per_wt' args are string varnames."""
        
        assert self.top_called
        assert not self.bottom_called
        assert (self.expected_mouter, self.expected_pouter) == (self.Mouter, 0)
        self.bottom_called = True
 
        nelts = self.Pouter * self.F * self.Tinner * self.Pinner
        us = self.weight_layout.unpadded_byte_stride
        bs = self.weight_layout.touter_byte_stride
        ps = utils.xdiv(bs, 4)   # since 'wp' is a 32-bit type

        k.emit()
        k.emit(f'// PfWeightReader.bottom()')
        k.emit(f'// One touter-step corresponds to (Pouter * F * Tinner * Pinner) = {nelts} W-array elements')
        k.emit(f'// unpadded_byte_stride = {us}, byte_stride = {bs}, pointer_stride = {ps}')

        if self.Tinner > 1:
            k.emit(f"// Since Tinner > 1, we ignore '{nt_in_per_wt}', and always increment the weight pointer '{self.wp}'.")
        else:
            k.emit("// FIXME optimize out mod-operator")
            k.emit(f"if (!(({tin} + {32*self.SW}) % {nt_in_per_wt}))")
            
        k.emit(f"{self.wp} += {ps};")
        

    def emit_test_kernel(self, k):
        dt32, SW = self.dtype.simd32, self.dtype.simd_width
        assert self.Pinner == SW  # assumed below
        
        k.emit('// Autogenerated by pirate_frb.cuda_generator')
        k.emit()
        k.emit('// For a high-level overview, see the long comment at the top of')
        k.emit('// pirate_frb/cuda_generator/PeakFinder.py')
        k.emit()
        k.emit('#include "../../include/pirate/PeakFindingKernel.hpp"')
        k.emit('#include "../../include/pirate/inlines.hpp"   // vec_equal()')
        k.emit()
        k.emit('#include <cstdio>')
        k.emit('#include <iostream>')
        k.emit()
        k.emit('namespace pirate {')
        k.emit()

        k.emit('// The test kernel does the following (schematically):')
        k.emit('//')
        k.emit('//   for (int tin = 0; tin < nt_in; tin += 32*SW)')
        k.emit('//       for (int mouter = 0; mouter < Mouter; mouter++)')
        k.emit('//           for (int Pouter = 0; pouter < Pouter; pouter++)')
        k.emit('//               call read_weights(), and write to out[]')
        k.emit('//')
        k.emit('// out: shape (nt_in/Dcore, Mouter*Minner, Pouter*Pinner)')
        k.emit('// in: shape (nt_in/(nt_in_per_wt*Tinner), Pouter, F, Tinner, Pinner)')
        k.emit('// nt_in: number of input time samples')
        k.emit('// nt_in_per_wt: time downsampling factor for weight array')
        k.emit('//')
        k.emit('// Caller is responsible for checking:')
        k.emit('//   - nt_in_per_wt is a power of two')
        k.emit('//   - If Tinner == 1, then nt_in_per_wt >= (32 * simd_width)')
        k.emit('//   - If Tinner > 1, then nt_in_per_wt == (32 * simd_width) / Tinner')
        k.emit('//   - nt_in is a mutliple of nt_in_per_wt')
        k.emit('//   - nt_in is a multiple of (32 * simd_width)')
        k.emit('//')
        k.emit('// Launch with 32 threads, 1 block.')
        k.emit()
        
        k.emit(f'__global__ void {self.test_kernel_name}(void *out_, const void *in_, uint nt_in, uint nt_in_per_wt)')
        k.emit(f'{{')
        k.emit(f'constexpr int Dcore = {self.Dcore};')
        k.emit(f'constexpr int Pouter = {self.Pouter};')
        k.emit(f'constexpr int Mouter = {self.Mouter};')
        k.emit(f'constexpr int Minner = {self.Minner};')
        k.emit(f'constexpr int log2_Minner = {utils.integer_log2(self.Minner)};')
        k.emit()
        k.emit(f'{dt32} *out = ({dt32} *) out_;')
        k.emit(f'const {dt32} *in = (const {dt32} *) in_;')

        k.emit()
        k.emit(f"// Apply per-lane offsets to 'out'.")
        k.emit(f'out += Pouter * (threadIdx.x & (Minner-1));   // m-offset')
        k.emit(f'out += Mouter * Minner * Pouter * (threadIdx.x >> log2_Minner);   // t-offset')

        self.top(k, 'in')

        k.emit()
        k.emit(f'for (uint tin = 0; tin < nt_in; tin += {32*SW}) {{')

        for mouter in range(self.Mouter):
            for pouter in range(self.Pouter):
                w = f'pfw_m{mouter}_p{pouter}'
                self.read_weights(k, w, mouter, pouter)
                k.emit()
                k.emit(f'// (mouter, pouter) = ({mouter}, {pouter})')
                k.emit(f'out[({mouter} * Minner * Pouter) + {pouter}] = {w};')
                k.emit()
        
        k.emit(f'// Advance output pointer by ({32*SW}/Dcore) time samples')
        k.emit(f'out += ({32*SW}/Dcore) * Mouter * Minner * Pouter;')

        self.bottom(k, 'tin', 'nt_in_per_wt')
        
        k.emit('}   // end of tin loop')
        k.emit('}   // end of cuda kernel')

        fs = self.frequency_subbands
        m_to_f = ', '.join(str(int(f)) for f,d in fs.m_to_fd)
        m_to_d = ', '.join(str(int(d)) for f,d in fs.m_to_fd)
        f_to_ilo = ', '.join(str(int(ilo)) for ilo,ihi in fs.f_to_irange)
        f_to_ihi = ', '.join(str(int(ihi)) for ilo,ihi in fs.f_to_irange)
        sb_counts = ', '.join(str(int(x)) for x in fs.subband_counts)
        
        k.emit('\n// Boilerplate to register the kernel when the library is loaded.')
        k.emit('namespace {')
        k.emit('struct register_hack {')
        k.emit('register_hack() {')
        k.emit('TestPfWeightReader::RegistryKey k;')
        k.emit(f'k.dtype = ksgpu::Dtype::native<{self.dtype.scalar}>();')
        k.emit(f'k.subband_counts = {{ {sb_counts} }};')
        k.emit(f'k.Dcore = {self.Dcore};')
        k.emit(f'k.Tinner = {self.Tinner};')
        k.emit(f'k.P = {self.P};')
        k.emit()
        k.emit('TestPfWeightReader::RegistryValue v;')
        k.emit(f'v.cuda_kernel = {self.test_kernel_name};')
        k.emit(f'v.Mouter = {self.Mouter};')
        k.emit(f'v.Minner = {self.Minner};')
        k.emit()
        k.emit(f'v.pf_weight_layout.dtype =  ksgpu::Dtype::native<{self.dtype.scalar}>();')
        k.emit(f'v.pf_weight_layout.F = {self.F};')
        k.emit(f'v.pf_weight_layout.P = {self.P};')
        k.emit(f'v.pf_weight_layout.Pouter = {self.Pouter};')
        k.emit(f'v.pf_weight_layout.Pinner = {self.Pinner};')
        k.emit(f'v.pf_weight_layout.Tinner = {self.Tinner};')
        k.emit(f'v.pf_weight_layout.touter_byte_stride = {self.weight_layout.touter_byte_stride};')
        k.emit(f'v.pf_weight_layout.validate();  // throws an exception if anything is wrong')
        k.emit()
        k.emit('// Checks consistency of python/C++ FrequencySubbands')
        k.emit(f'FrequencySubbands fs( {{ {sb_counts} }} );')
        k.emit(f'xassert_eq(fs.F, {self.F});')
        k.emit(f'xassert_eq(fs.M, {self.M});')
        k.emit(f'xassert(vec_equal(fs.m_to_f, {{ {m_to_f} }}));')
        k.emit(f'xassert(vec_equal(fs.m_to_d, {{ {m_to_d} }}));')
        k.emit(f'xassert(vec_equal(fs.f_to_ilo, {{ {f_to_ilo} }}));')
        k.emit(f'xassert(vec_equal(fs.f_to_ihi, {{ {f_to_ihi} }}));')
        k.emit()
        k.emit('bool debug = false;')
        k.emit('TestPfWeightReader::registry().add(k, v, debug);')
        k.emit('} // register_hack constructor')
        k.emit('}; // struct register hack')
        k.emit('register_hack hack;')
        k.emit('} // anonymous namespace')
        k.emit()
        k.emit('}   // namespace pirate')

        
    @classmethod
    def write_test_kernel(cls, filename):
        """Called from 'autogenerate_kernel.py' in the toplevel pirate directory."""
        
        basename = os.path.basename(filename)

        # Typical basename: pf_weight_reader_test_fp32_f11_f6_f3_f1_Dcore8_P13_Tinner2.cu
        m = re.fullmatch(r'pf_weight_reader_test_(fp\d+)_((?:f\d+_)*f\d+)_Dcore(\d+)_P(\d+)_Tinner(\d+)\.cu', basename)
        if not m:
            raise RuntimeError(f"Couldn't match filename '{filename}'")

        dtype = Dtype(m.group(1))
        frequency_subbands = FrequencySubbands.from_fstr(m.group(2))
        Dcore, P, Tinner = int(m.group(3)), int(m.group(4)), int(m.group(5))
        
        pf_weight_reader = PfWeightReader(frequency_subbands, dtype, Dcore, P, Tinner)

        if pf_weight_reader.test_kernel_basename != basename:
            raise RuntimeError("PfWeightReader.write_test_kernel(): internal error: expected "
                               + f" {pf_weight_reader.test_kernel_basename=} and {basename=} to be equal")
        
        k = Kernel()
        pf_weight_reader.emit_test_kernel(k)

        with open(filename,'w') as f:
            with utils.clang_formatter(f) as ff:
                k.write(ff)


####################################################################################################


class PfOutput2:
    def __init__(self, dtype, Dout):
        """
        Input: partially reduced Z_{st} array, with associated 32-bit argmax values.
        Here, "s" is a spectator index (from the perspective of the PfOutput2 microkernel).
        In the larger kernel, "s" is a combination of (m,p,tlo). The register assignment is:
         
          [float32]  lane <-> s(0,L) tout(0,5-L)
          [float16]  simd <-> s(0)    lane <-> s(1,L) tout(0,6-L)

        Output: as an "outer" t-loop is iterated, the Z_{st} array gets reduced over
        spectator indices, and two length nt_out=(nt_in/Dout) array gets incrementally
        written to global memory (see below).

        Generated code looks like this:

          constexpr int SW = 128 / sizeof(dtype);  // simd width
        
          // Initialization of output pointers is not supplied by PfOutput2.
          T32 *zp = ...;   // per-warp output pointer, points to length (nt_in/(Dout*SW))
          uint *ap = ...;  // per-warp "argmax" pointer, points to length (nt_in/(Dout*SW))
          
          // Loop over t-values is not supplied by PfOutput2.
          for (uint tin = 0; tin < nt_in; t += 32*SW) {
        
              // Multiple calls to PfOutput2.apply_inner().
        
              pf_output2.apply_inner(k, zname1, amax_names1);
                // ...
              pf_output2.apply_inner(k, zname2, amax_names2);
                // ...

              // One call to PfOutput2.apply_outer(), at bottom of t-loop, to write
              // output incrementally. The'zout' and 'aout' pointers are "owned" by
              // the PfOutput2 class, and these pointers will be incremented, as data
              // gets written to global memory.

              pf_output2.apply_outer(k, 'zp', 'ap', 'tin', 'nt_in');
          }
        """
        
        self.Dout = Dout
        self.dtype = dtype = Dtype(dtype)
        self.L = utils.integer_log2(Dout)
        self.SW = dtype.simd_width
        self.dt32 = dtype.simd32

        # Assumed in this placeholder version of PfOutput2, but may change in the future.
        # If it does change, then changes should be reflected in PeakFindingKernelParams2::validate()
        # and in code that makes random unit tests.
        assert utils.is_power_of_two(Dout)
        assert self.SW <= Dout <= 32

        self.test_kernel_name = f'pf_output2_test_fp{32//self.SW}_Dout{Dout}'
        self.test_kernel_basename = self.test_kernel_name + '.cu'
        self.apply_inner_called = False
        self.apply_outer_called = False
        
        
    def apply_inner(self, k, z, alist):
        """
        The 'z' arg is the name of a variable containing Z-values to be reduced (dtype=dt32).
        The 'alist' arg is a list of varnames for corresponding argmax values (length 1,2 for fp32,fp16).
        Contents of the 'alist' registers are opaque "tokens" in class PfOutput2.
        """

        dtype, dt32, L, SW = self.dtype, self.dt32, self.L, self.SW
        
        assert not self.apply_outer_called
        assert len(alist) == SW

        k.emit()
        k.emit(f'// PfOutput2.apply_inner() called: {z=}, {alist=}')
        k.emit('// These represent partially reduced Z-values, with associated 32-bit argmax values')
        k.emit('// Register assignment is:')

        self._emit_za_register_assignment(k)

        if not self.apply_inner_called:
            k.emit(f'// First call to apply_inner() just initializes zinner, ainner*')
            k.emit(f'{dt32} zinner = {z};')
            for s in range(SW):
                k.emit(f'uint ainner{s} = {alist[s]};')
            self.apply_inner_called = True
            return

        k.emit(f'// Absorbing {z=}, {alist=} into zinner, ainner*')

        if dtype.nbits == 32:
            k.emit(f'ainner0 = ({z} <= zinner) ? ainner0 : {alist[0]};')
            k.emit(f'zinner = fmaxf(zinner, {z});')
        elif dtype.scalar == '__half':
            cmp1, cmp2 = k.get_tmp_rname(2)
            k.emit(f'__half2 {cmp1} = __hle2({z}, zinner);')
            k.emit(f'uint {cmp2} = *reinterpret_cast<uint*>(&{cmp1});  // __half2 -> uint')
            k.emit(f'ainner0 = ({cmp2} & 0xffffu) ? ainner0 : {alist[0]};')
            k.emit(f'ainner1 = ({cmp2} & 0xffff0000u) ? ainner1 : {alist[1]};')
            k.emit(f'zinner = __hmax2(zinner, {z});')
        else:
            raise RuntimeError('should never get here')

    
    def apply_outer(self, k, zout, aout, tin, nt_in):
        """
        The 'zout' arg is a per-warp (dt32 *) varname.
        The 'aout' arg is a per-warp (uint *) varname.
        The 'tin' and 'nt_in' args are uint varnames.

        NOTE: The'zout' and 'aout' pointers are "owned" by the PfOutput2 class, and these
        pointers will be incremented, as data gets written to global memory.
        """
        
        dtype, L, SW = self.dtype, self.L, self.SW

        assert self.apply_inner_called
        assert not self.apply_outer_called
        self.apply_outer_called = True
        
        k.emit()
        k.emit(f'// PfOutput2.apply_outer() called: {zout=}, {aout}, {tin=}, {nt_in=}')
        k.emit(f'// In this placeholder implementation, we ignore values of tin/nt_in,')
        k.emit(f'// and do partial writes directly to global memory. (FIXME suboptimal)')
        k.emit(f'// Starting point is zinner, {srange("ainner",SW,sep=", ")}, with register assignemnt')

        self._emit_za_register_assignment(k)

        z = 'zinner'
        
        if dtype.scalar != 'float':
            z = 'zinner0'
            lo, hi = k.get_tmp_rname(2)
            k.emit(f'\n// Thread-local reduction from (__half2 zinner) -> (__half zinner0)')
            k.emit(f'__half zinner0 = __low2half(zinner);')
            k.emit(f'__half zinner1 = __high2half(zinner);')
            k.emit(f'ainner0 = (zinner0 < zinner1) ? ainner1 : ainner0;')
            k.emit(f'zinner0 = __hmax(zinner0, zinner1);')

        for b in range(L+1-SW):
            zz, aa = k.get_tmp_rname(2);
            k.emit(f'\n// Reduce {z}, ainner0 over lanes, stride={2**b}')
            k.emit(f'{dtype.scalar} {zz} = __shfl_sync(~0u, {z}, threadIdx.x ^ {2**b});')
            k.emit(f'uint {aa} = __shfl_sync(~0u, ainner0, threadIdx.x ^ {2**b});')
            k.emit(f'ainner0 = ({z} < {zz}) ? {aa} : ainner0;')
            k.emit(f'{z} = {self.dtype.max_scalar(z,zz)};')

        if dtype.scalar == 'float':
            k.emit(f'\n// Now {z}, ainner0 have been fully reduced, with register assignment:')
            k.emit(f'//   lane <-> {srange("s",L)} {srange("tout",5-L)}')
            
            if L >= 1:
                k.emit(f'// Gather onto initial lanes of warp, obtaining register assignment:')
                k.emit(f'//   {srange("l",5-L)} <-> {srange("tout",5-L)}')
                k.emit(f'{z} = __shfl_sync(~0u, {z}, threadIdx.x << {L});')
                k.emit(f'ainner0 = __shfl_sync(~0u, ainner0, threadIdx.x << {L});')
        
        elif dtype.scalar == '__half':
            k.emit(f'\n// Now {z}, ainner0 have been fully reduced, with register assignment:')
            k.emit(f'//   lane <-> {srange("s",1,L)} {srange("tout",6-L)}')
            
            k.emit(f'// Gather {z} into initial lanes of warp, and pack to (__half2 zinner):')
            k.emit(f'//   [zinner] simd <-> tout0,  {srange("l",5-L)} <-> {srange("tout",1,6-L)}')
            
            lo, hi = k.get_tmp_rname(2)
            k.emit(f'__half {lo} = __shfl_sync(~0u, {z}, (threadIdx.x << {L}));')
            k.emit(f'__half {hi} = __shfl_sync(~0u, {z}, (threadIdx.x << {L}) + {1<<(L-1)});')
            k.emit(f'zinner = __halves2half2({lo}, {hi});')

            if L >= 2:
                k.emit(f'// Gather ainner0 onto initial lanes of warp:')
                k.emit(f'//   [ainner0] {srange("l",6-L)} <-> {srange("tout",6-L)}')
                k.emit(f'ainner0 = __shfl_sync(~0u, ainner0, threadIdx.x << {L-1});')

        else:
            raise RuntimeError('should never get here')

        k.emit(f'\n// Now write zinner, ainner0 to global memory (may be partial writes)')
        k.emit(f'// This code could be improved, but apply_outer() is currently a placeholder anyway.')
        
        nz = 2**(5-L)
        na = 2**(4+SW-L)
        laneId = k.get_tmp_rname()
        
        k.emit(f'uint {laneId} = (threadIdx.x & 0x1f); // laneId')
        k.emit(f'if ((threadIdx.x & 0x1f) < {nz})')
        k.emit(f'    {zout}[{laneId}] = zinner;')
        k.emit(f'if ((threadIdx.x & 0x1f) < {na})')
        k.emit(f'    {aout}[{laneId}] = ainner0;')
        k.emit(f'{zout} += {nz};')
        k.emit(f'{aout} += {na};')
        
        k.emit(f'\n// PfOutput2.apply_outer() ends here')
        
    
    def _emit_za_register_assignment(self, k):
        """Helper function, called by apply_inner() and apply_outer()."""
        
        dtype, L = self.dtype, self.L
        
        if dtype.scalar == 'float':
            k.emit(f'//   [z,a0]: lane <-> {srange("s",L)} {srange("tout",5-L)}')
        elif dtype.scalar == '__half':            
            k.emit(f'//   [z]: simd <-> s0  lane <-> {srange("s",1,L)} {srange("tout",6-L)}')
            k.emit(f'//   [a0+a1]:  reg <-> s0   lane <-> {srange("s",1,L)} {srange("tout",6-L)}')
        else:
            raise RuntimeError('should never get here')

        
    @classmethod
    def write_test_kernel(cls, filename):
        """Called from 'autogenerate_kernel.py' in the toplevel pirate directory."""
        
        basename = os.path.basename(filename)
        
        m = re.fullmatch(r'pf_output2_test_(fp\d+)_Dout(\d+)\.cu', basename)
        if not m:
            raise RuntimeError(f"Couldn't match filename '{filename}'")

        dtype = Dtype(m.group(1))
        Dout = int(m.group(2))

        pf_output = PfOutput2(dtype, Dout)
        assert pf_output.test_kernel_basename == basename

        k = Kernel()
        SW = pf_output.SW
        
        k.emit('// Autogenerated by pirate_frb.cuda_generator')
        k.emit()
        k.emit('// For a high-level overview, see the long comment at the top of')
        k.emit('// pirate_frb/cuda_generator/PeakFinder.py')
        k.emit()
        k.emit('#include <cstdio>')
        k.emit('#include <iostream>')
        k.emit('#include "../../include/pirate/PeakFindingKernel.hpp"')
        k.emit()
        k.emit('namespace pirate {')
        k.emit()

        k.emit(f'// Use 4 calls to apply_inner() inside t-loop.')
        k.emit(f'// Thus, the number of reduced spectator indices is 4*Dout = 4*{Dout} = {4*Dout}')
        k.emit(f'//')
        k.emit(f'// zout: shape (nt_in//Dout) == (nt_in//{Dout})')
        k.emit(f'// aout32: shape (nt_in//Dout) == (nt_in//{Dout})')
        k.emit(f'// zin: shape (4, nt_in)')
        k.emit(f'// ain32: shape (4, nt_in)')
        k.emit(f'// nt_in: number of input time samples')
        k.emit('//')
        k.emit('// Caller is responsible for checking:')
        k.emit('//   - nt_in is a multiple of (32 * simd_width)')
        k.emit()
        k.emit(f'// Call with 32 threads, and 1 threadblock.')

        k.emit(f'__global__ void {pf_output.test_kernel_name}(void *zout_, uint *aout32, void *zin_, uint *ain32, uint nt_in)')
        k.emit(f'{{')

        if dtype.scalar == 'float':
            k.emit(f'float *zout32 = (float *) zout_;')
            k.emit(f'float *zin32 = (float *) zin_;')
        elif dtype.scalar == '__half':
            k.emit(f'__half2 *zout32 = (__half2 *) zout_;')
            k.emit(f'__half2 *zin32 = (__half2 *) zin_;')
            k.emit(f'uint2 *ain64 = (uint2 *) ain32;')
        else:
            raise RuntimeError('should never get here')

        k.emit(f'\nfor (uint tin = 0; tin < nt_in; tin += {32*SW}) {{')
        
        for s in range(4):
            if dtype.scalar == 'float':
                p = f'{s}*nt_in + ' if (s > 0) else ''
                k.emit(f'float z{s} = zin32[{p}threadIdx.x];')
                k.emit(f'uint a{s} = ain32[{p}threadIdx.x];')
                pf_output.apply_inner(k, f'z{s}', [f'a{s}'])
            elif dtype.scalar == '__half':
                p = f'{s}*(nt_in>>1) + ' if (s > 0) else ''
                k.emit(f'__half2 z{s} = zin32[{p}threadIdx.x];')
                k.emit(f'uint2 a{s} = ain64[{p}threadIdx.x];')
                pf_output.apply_inner(k, f'z{s}', [f'a{s}.x', f'a{s}.y'])
            else:
                raise RuntimeError('should never get here')
                
            k.emit()

        k.emit(f'// Advance input pointers')
        k.emit(f'zin32 += 32;')
        k.emit(f'ain{32*dtype.simd_width} += 32;')  # either 'ain32' or 'ain64'
        k.emit()

        pf_output.apply_outer(k, 'zout32', 'aout32', 'tin', 'nt_in')
        
        k.emit('}   // end of tin loop')
        k.emit('}   // end of cuda kernel')

        k.emit('\n// Boilerplate to register the kernel when the library is loaded.')
        k.emit('namespace {')
        k.emit('struct register_hack {')
        k.emit('register_hack() {')
        k.emit('TestPfOutput2::RegistryKey k;')
        k.emit(f'k.dtype = ksgpu::Dtype::native<{dtype.scalar}>();')
        k.emit(f'k.Dout = {pf_output.Dout};')
        k.emit()
        k.emit('TestPfOutput2::RegistryValue v;')
        k.emit(f'v.cuda_kernel = {pf_output.test_kernel_name};')
        k.emit()
        k.emit('bool debug = false;')
        k.emit('TestPfOutput2::registry().add(k, v, debug);')
        k.emit('} // register_hack constructor')
        k.emit('}; // struct register hack')
        k.emit('register_hack hack;')
        k.emit('} // anonymous namespace')
        k.emit()
        
        k.emit('}   // namespace pirate')

        with open(filename,'w') as f:
            with utils.clang_formatter(f) as ff:
                k.write(ff)
